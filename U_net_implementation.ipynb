{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597884132917",
   "display_name": "Python 3.7.7 64-bit ('tf-learning': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net model\n",
    "Network architecture called \"U-Net\". The name of this network architecture comes from it's U-like shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-nets are commonly used for image segmentation, this architecture features a series of down-convolutions connected by max-pooling operations, followed by a series of up-convolutions connected by upsampling and concatenation operations. Each of the down-convolutions is also connected directly to the concatenation operations in the upsampling portion of the network. For more detail on the U-Net architecture, have a look at the original U-Net paper by Ronneberger et al. 2015.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# Import the elements we'll need to build your U-Net\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.engine import Input, Model\n",
    "from keras.layers import Conv3D, MaxPooling3D, UpSampling3D, Activation, BatchNormalization, PReLU, Deconvolution3D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.merge import concatenate\n",
    "# Set the image shape to have the channels in the first dimension\n",
    "K.set_image_data_format(\"channels_first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The \"depth\" of  U-Net\n",
    "The \"depth\" of our U-Net is equal to the number of down-convolutions we will use. U-Net depth of 2, meaning we'll have 2 down-convolutions in your network.\n",
    "\n",
    "## Input layer and its \"depth\"\n",
    "we will be doing 3D image segmentation, which is to say that, in addition to \"height\" and \"width\", our input layer will also have a \"length\".\n",
    "\n",
    "The shape of the input layer is (num_channels, height, width, length), where num_channels you can think of like color channels in an image, height, width and length are just the size of the input.\n",
    "\n",
    "here, the values will be:\n",
    "\n",
    "num_channels: 4\n",
    "height: 160\n",
    "width: 160\n",
    "length: 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor 'input_1:0' shape=(None, 4, 160, 160, 16) dtype=float32>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# input layer tensor of the shape you'll use in the assignment\n",
    "input_layer = Input(shape=(4, 160, 160, 16))\n",
    "input_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the tensor shape has a '?' as the very first dimension. This will be the batch size. So the dimensions of the tensor are: (batch_size, num_channels, height, width, length)\n",
    "\n",
    "## Contracting (downward) path\n",
    "Here we'll start by constructing the downward path in your network (the left side of the U-Net). The (height,width, length) of the input gets smaller as you move down this path, and the number of channels increases.\n",
    "\n",
    "Depth 0\n",
    "By \"depth 0\" here, we're referring to the depth of the first down-convolution in the U-net.\n",
    "\n",
    "The number of filters is specified for each depth and for each layer within that depth.\n",
    "\n",
    "The formula to use for calculating the number of filters is:\n",
    "filtersi=32×(2i)\n",
    "Where i is the current depth.\n",
    "\n",
    "So at depth i=0:\n",
    "filters0=32×(20)=32\n",
    "## Layer 0\n",
    "There are two convolutional layers for each depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor 'conv3d_1/add:0' shape=(None, 32, 160, 160, 16) dtype=float32>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Conv3D tensor with 32 filters\n",
    "down_depth_0_layer_0 = Conv3D(filters=32, \n",
    "                              kernel_size=(3,3,3),\n",
    "                              padding='same',\n",
    "                              strides=(1,1,1)\n",
    "                              )(input_layer)\n",
    "down_depth_0_layer_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that with 32 filters, the result you get above is a tensor with 32 channels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor 'activation_1/Relu:0' shape=(None, 32, 160, 160, 16) dtype=float32>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#a relu activation to layer 0 of depth 0\n",
    "down_depth_0_layer_0 = Activation('relu')(down_depth_0_layer_0)\n",
    "down_depth_0_layer_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth 0, Layer 1\n",
    "For layer 1 of depth 0, the formula for calculating the number of filters is:\n",
    "\n",
    "filters[i]=32×(2pow(i))×2\n",
    " \n",
    "Where  i  is the current depth.\n",
    "\n",
    "Notice that the ' × 2 ' at the end of this expression isn't there for layer 0.\n",
    "So at depth  i=0  for layer 1:\n",
    "filters[0]=32×(20)×2=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor 'activation_2/Relu:0' shape=(None, 64, 160, 160, 16) dtype=float32>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Conv3D layer with 64 filters and add relu activation\n",
    "down_depth_0_layer_1 = Conv3D(filters=64, \n",
    "                kernel_size=(3,3,3),\n",
    "                padding='same',\n",
    "                strides=(1,1,1)\n",
    "               )(down_depth_0_layer_0)\n",
    "down_depth_0_layer_1 = Activation('relu')(down_depth_0_layer_1)\n",
    "down_depth_0_layer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max pooling\n",
    "Within the U-Net architecture, there is a max pooling operation after each of the down-convolutions (not including the last down-convolution at the bottom of the U). In general, this means we'll add max pooling after each down-convolution up to (but not including) the depth - 1 down-convolution (since we started counting at 0).\n",
    "\n",
    "Here:\n",
    "\n",
    "The overall depth of the U-Net you're constructing is 2\n",
    "So the bottom of  U is at a depth index of:  2−1=1 .\n",
    "So far we've only defined the  depth=0  down-convolutions, so the next thing to do is add max pooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor 'max_pooling3d_1/MaxPool3D:0' shape=(None, 64, 80, 80, 8) dtype=float32>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#  max pooling layer\n",
    "down_depth_0_layer_pool = MaxPooling3D(pool_size=(2,2,2))(down_depth_0_layer_1)\n",
    "down_depth_0_layer_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth 1, Layer 0\n",
    "At depth 1, layer 0, the formula for calculating the number of filters is:\n",
    "filtersi=32×(2i)\n",
    " \n",
    "Where  i  is the current depth.\n",
    "\n",
    "So at depth  i=1 :\n",
    "filters[1]=32×(21)=64\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor 'activation_3/Relu:0' shape=(None, 64, 80, 80, 8) dtype=float32>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Conv3D layer to your network with relu activation\n",
    "down_depth_1_layer_0 = Conv3D(filters=64, \n",
    "                kernel_size=(3,3,3),\n",
    "                padding='same',\n",
    "                strides=(1,1,1)\n",
    "               )(down_depth_0_layer_pool)\n",
    "down_depth_1_layer_0 = Activation('relu')(down_depth_1_layer_0)\n",
    "down_depth_1_layer_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth 1, Layer 1\n",
    "For layer 1 of depth 1 the formula we'll use for number of filters is:\n",
    "filters[i]=32×(2i)×2\n",
    " \n",
    "Where  i  is the current depth.\n",
    "\n",
    "Notice that the ' ×2 ' at the end of this expression isn't there for layer 0.\n",
    "So at depth  i=1 :\n",
    "\n",
    "filters[0]=32×(21)×2=128\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor 'activation_4/Relu:0' shape=(None, 128, 80, 80, 8) dtype=float32>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "#  another Conv3D with 128 filters to your network.\n",
    "down_depth_1_layer_1 = Conv3D(filters=128, \n",
    "                kernel_size=(3,3,3),\n",
    "                padding='same',\n",
    "                strides=(1,1,1)\n",
    "               )(down_depth_1_layer_0)\n",
    "down_depth_1_layer_1 = Activation('relu')(down_depth_1_layer_1)\n",
    "down_depth_1_layer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No max pooling at depth 1 (the bottom of the U)\n",
    "When we get to the \"bottom\" of the U-net, we don't need to apply max pooling after the convolutions.\n",
    "\n",
    "## Expanding (upward) Path\n",
    "Now we'll work on the expanding path of the U-Net, (going up on the right side ). The image's (height, width, length) all get larger in the expanding path.\n",
    "\n",
    "## Depth 0, Up sampling layer 0\n",
    "We'll use a pool size of (2,2,2) for upsampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor 'up_sampling3d_1/concat_2:0' shape=(None, 128, 160, 160, 16) dtype=float32>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# an upsampling operation to your network\n",
    "up_depth_0_layer_0 = UpSampling3D(size=(2,2,2))(down_depth_1_layer_1)\n",
    "up_depth_0_layer_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate upsampled depth 0 with downsampled depth 0\n",
    "Now we'll apply a concatenation operation using the layers that are both at the same depth of 0.\n",
    "\n",
    "up_depth_0_layer_0: shape is (?, 128, 160, 160, 16)\n",
    "depth_0_layer_1: shape is (?, 64, 160, 160, 16)\n",
    "\n",
    "\n",
    "If they're the same, then they can be concatenated along axis 1 (the channel axis).\n",
    "The (height, width, length) is (160, 160, 16) for both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tensor(\"up_sampling3d_1/concat_2:0\", shape=(None, 128, 160, 160, 16), dtype=float32)\n\nTensor(\"activation_2/Relu:0\", shape=(None, 64, 160, 160, 16), dtype=float32)\n"
    }
   ],
   "source": [
    "# Print the shape of layers to concatenate\n",
    "print(up_depth_0_layer_0)\n",
    "print()\n",
    "print(down_depth_0_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor 'concatenate_1/concat:0' shape=(None, 192, 160, 160, 16) dtype=float32>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# concatenation along axis 1\n",
    "up_depth_1_concat = concatenate([up_depth_0_layer_0,\n",
    "                                 down_depth_0_layer_1],\n",
    "                                axis=1)\n",
    "up_depth_1_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the upsampling layer had 128 channels, and the down-convolution layer had 64 channels so that when concatenated, the result has 128 + 64 = 192 channels.\n",
    "\n",
    "## Up-convolution layer 1\n",
    "The number of filters for this layer will be set to the number of channels in the down-convolution's layer 1 at the same depth of 0 (down_depth_0_layer_1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor 'activation_2/Relu:0' shape=(None, 64, 160, 160, 16) dtype=float32>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "down_depth_0_layer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "number of filters: 64\n"
    }
   ],
   "source": [
    "print(f\"number of filters: {down_depth_0_layer_1._keras_shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor 'activation_5/Relu:0' shape=(None, 64, 160, 160, 16) dtype=float32>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Conv3D up-convolution with 64 filters to  network\n",
    "up_depth_1_layer_1 = Conv3D(filters=64, \n",
    "                            kernel_size=(3,3,3),\n",
    "                            padding='same',\n",
    "                            strides=(1,1,1)\n",
    "                           )(up_depth_1_concat)\n",
    "up_depth_1_layer_1 = Activation('relu')(up_depth_1_layer_1)\n",
    "up_depth_1_layer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up-convolution depth 0, layer 2\n",
    "At layer 2 of depth 0 in the up-convolution the next step will be to add another up-convolution. The number of filters we'll want to use for this next up-convolution will need to be equal to the number of filters in the down-convolution depth 0 layer 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tensor(\"activation_2/Relu:0\", shape=(None, 64, 160, 160, 16), dtype=float32)\nnumber of filters: 64\n"
    }
   ],
   "source": [
    "print(down_depth_0_layer_1)\n",
    "print(f\"number of filters: {down_depth_0_layer_1._keras_shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the number of channels / filters in down_depth_0_layer_1 is 64.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor 'activation_6/Relu:0' shape=(None, 64, 160, 160, 16) dtype=float32>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# Conv3D up-convolution with 64 filters to your network\n",
    "up_depth_1_layer_2 = Conv3D(filters=64, \n",
    "                            kernel_size=(3,3,3),\n",
    "                            padding='same',\n",
    "                            strides=(1,1,1)\n",
    "                           )(up_depth_1_layer_1)\n",
    "up_depth_1_layer_2 = Activation('relu')(up_depth_1_layer_2)\n",
    "up_depth_1_layer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Convolution\n",
    "For the final convolution, we will set the number of filters to be equal to the number of classes in our input data.\n",
    "\n",
    "we will be using data with 3 classes, namely:\n",
    "\n",
    "1: edema\n",
    "\n",
    "2: non-enhancing tumor\n",
    "\n",
    "3: enhancing tumor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor 'conv3d_7/add:0' shape=(None, 3, 160, 160, 16) dtype=float32>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# final Conv3D with 3 filters to your network.\n",
    "final_conv = Conv3D(filters=3, #3 categories \n",
    "                    kernel_size=(1,1,1),\n",
    "                    padding='valid',\n",
    "                    strides=(1,1,1)\n",
    "                    )(up_depth_1_layer_2)\n",
    "final_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation for final convolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor 'activation_7/Sigmoid:0' shape=(None, 3, 160, 160, 16) dtype=float32>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# sigmoid activation to your final convolution.\n",
    "final_activation = Activation('sigmoid')(final_conv)\n",
    "final_activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and compile the model\n",
    "model = Model(inputs=input_layer, outputs=final_activation)\n",
    "model.compile(optimizer=Adam(lr=0.00001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 4, 160, 160,  0                                            \n__________________________________________________________________________________________________\nconv3d_1 (Conv3D)               (None, 32, 160, 160, 3488        input_1[0][0]                    \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 32, 160, 160, 0           conv3d_1[0][0]                   \n__________________________________________________________________________________________________\nconv3d_2 (Conv3D)               (None, 64, 160, 160, 55360       activation_1[0][0]               \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 64, 160, 160, 0           conv3d_2[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling3d_1 (MaxPooling3D)  (None, 64, 80, 80, 8 0           activation_2[0][0]               \n__________________________________________________________________________________________________\nconv3d_3 (Conv3D)               (None, 64, 80, 80, 8 110656      max_pooling3d_1[0][0]            \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 64, 80, 80, 8 0           conv3d_3[0][0]                   \n__________________________________________________________________________________________________\nconv3d_4 (Conv3D)               (None, 128, 80, 80,  221312      activation_3[0][0]               \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 128, 80, 80,  0           conv3d_4[0][0]                   \n__________________________________________________________________________________________________\nup_sampling3d_1 (UpSampling3D)  (None, 128, 160, 160 0           activation_4[0][0]               \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 192, 160, 160 0           up_sampling3d_1[0][0]            \n                                                                 activation_2[0][0]               \n__________________________________________________________________________________________________\nconv3d_5 (Conv3D)               (None, 64, 160, 160, 331840      concatenate_1[0][0]              \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 64, 160, 160, 0           conv3d_5[0][0]                   \n__________________________________________________________________________________________________\nconv3d_6 (Conv3D)               (None, 64, 160, 160, 110656      activation_5[0][0]               \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 64, 160, 160, 0           conv3d_6[0][0]                   \n__________________________________________________________________________________________________\nconv3d_7 (Conv3D)               (None, 3, 160, 160,  195         activation_6[0][0]               \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 3, 160, 160,  0           conv3d_7[0][0]                   \n==================================================================================================\nTotal params: 833,507\nTrainable params: 833,507\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "# Print out a summary of the model  created\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use these techniques in our project in order to segemnet brain tumors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}